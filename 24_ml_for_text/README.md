# Проект для «Викишоп» с BERT и Classic ML

Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.

Обучим модель классифицировать комментарии на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности правок.

Построим модель со значением метрики качества *F1* не меньше 0.75.

**Инструкция по выполнению проекта**

1. Загрузим и подготовим данные.
2. Обучим разные модели.
3. Сделаем выводы.

Для выполнения проекта применять *BERT* необязательно, но я попробую.

**Описание данных**

Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак.

## Общий вывод

- Модель Случайного леса на основе эмбеддингов, имеет результат метрики `f1` равный `0.889`
- Модель LGBM на основе tf-idf, имеет результат метрики `f1` равный `0.854`

В данном исследовании можно сказать что модель на основе tf-idf почти такая же по точность, как и модель на основе эмбеддингов.
Но также стоит учесть то что в условиях ограниченных ресурсов эмбединги были рассчитаны не для всего датафрейма а только для выборки из 512 строк. Поэтому при наличии большего количества вычислительных мощностей модель рассчитанная на эмбеддингах даст более точный ответ. И это также показывает, что даже с небольшим количеством данных, получается очень высокая точность при использовании эмбеддингов.
